{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24ec55a-f3ae-442d-b86d-0ef05460bbae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from FuncoesAuxiliares import get_regressor, get_feature_selector, selecionar_comp, get_dados, arrumar_dados_treinamento, filtrar_colunas, get_novos_dados\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, root_mean_squared_error, f1_score\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db66e9b-5ca8-4fed-b5b2-116d81038fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divisão NILC, treino: (735, 73), teste: (369, 73), se possuem o mesmo tanto de features: True\n",
      "Divisão NILC_merge, treino: (858, 73), teste: (369, 73), se possuem o mesmo tanto de features: True\n",
      "Divisão iR4S, treino: (735, 658), teste: (369, 658), se possuem o mesmo tanto de features: True\n",
      "Divisão iR4S_merge, treino: (858, 658), teste: (369, 658), se possuem o mesmo tanto de features: True\n",
      "Divisão iR4S-F, treino: (735, 226), teste: (369, 226), se possuem o mesmo tanto de features: True\n",
      "Divisão iR4S-F_merge, treino: (858, 226), teste: (369, 226), se possuem o mesmo tanto de features: True\n",
      "Divisão nao_neurais, treino: (735, 730), teste: (369, 730), se possuem o mesmo tanto de features: True\n",
      "Divisão nao_neurais_merge, treino: (858, 730), teste: (369, 730), se possuem o mesmo tanto de features: True\n",
      "Divisão neurais, treino: (735, 9), teste: (369, 9), se possuem o mesmo tanto de features: True\n",
      "Divisão neurais_merge, treino: (858, 9), teste: (369, 9), se possuem o mesmo tanto de features: True\n",
      "Divisão completo, treino: (858, 738), teste: (369, 738), se possuem o mesmo tanto de features: True\n",
      "Divisão completo_sem_merge, treino: (735, 738), teste: (369, 738), se possuem o mesmo tanto de features: True\n"
     ]
    }
   ],
   "source": [
    "lista_divisoes = ['NILC', 'NILC_merge', 'iR4S', 'iR4S_merge','iR4S-F', 'iR4S-F_merge', 'nao_neurais', 'nao_neurais_merge', 'neurais', 'neurais_merge', 'completo', 'completo_sem_merge']\n",
    "for l in lista_divisoes:\n",
    "    dados1 = arrumar_dados_treinamento(1, l)\n",
    "    dados2 = get_novos_dados(1, l)['teste']\n",
    "    print(f\"Divisão {l}, treino: {dados1.shape}, teste: {dados2.shape}, se possuem o mesmo tanto de features: {dados1.shape[1] == dados2.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934dbfc-9582-416e-84e4-c2f34e1d3feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aed478-01c5-4649-a737-af8a73148580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcular_resultados(y, y_hat):\n",
    "    ACC = accuracy_score(y, y_hat)\n",
    "    RMSE = root_mean_squared_error(y, y_hat)\n",
    "    QWK = cohen_kappa_score(y, y_hat, weights='quadratic')\n",
    "    KAPPA = cohen_kappa_score(y, y_hat, labels=[0, 1, 2, 3, 4, 5])\n",
    "    F1 = f1_score(y, y_hat, average='weighted')\n",
    "    dic = {'ACC': ACC, 'RMSE': RMSE, 'QWK': QWK, 'KAPPA': KAPPA, 'F1': F1}\n",
    "    return dic\n",
    "    \n",
    "def arrumar_notas(notas):\n",
    "    novas_notas = []\n",
    "    for n in notas:\n",
    "        arredondada = int(round(n))\n",
    "        if arredondada > 5:\n",
    "            arredondada = 5\n",
    "        if arredondada < 0:\n",
    "            arredondada = 0\n",
    "        novas_notas.append(arredondada)\n",
    "    return novas_notas\n",
    "\n",
    "\n",
    "def treinar_classificador(parametros, quantidade_vezes):\n",
    "    #retorna a média e desvio padrao em kappa e f1\n",
    "    dados_teste = get_novos_dados(parametros['comp'], parametros['tipo'])\n",
    "    teste = dados_teste['teste']\n",
    "    y_teste = teste['competencia']\n",
    "    teste_final = teste.drop('competencia', axis=1)\n",
    "    lista_dic = []\n",
    "    features_selecionadas = []\n",
    "    for vez in range(1, quantidade_vezes+1):\n",
    "        rl = get_regressor(parametros['comp'], parametros['classifier'], parametros['tipo'], params=parametros['p'])\n",
    "        #inferir no teste\n",
    "        x = teste_final.values\n",
    "        notas = rl.predict(x)\n",
    "        y_hat = arrumar_notas(notas)\n",
    "        dic_teste = calcular_resultados(y_teste, y_hat)\n",
    "        if quantidade_vezes != 1:\n",
    "            dic_teste['soma_teste'] = dic_teste['F1'] + dic_teste['KAPPA']\n",
    "            lista_dic.append(dic_teste)\n",
    "        else:\n",
    "            lista_dic.append( {\"soma_teste\": dic_teste['F1'] + dic_teste['KAPPA']   }  ) \n",
    "    return lista_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2547b-85d7-4893-9b31-a535e9d579a6",
   "metadata": {},
   "source": [
    "## Treinar Regressor Linear ou Florestas Aleatórias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fb0e4-3376-4f85-b955-31df7fab4b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conjunto = ['NILC_merge', 'iR4S_merge', 'iR4S-F_merge', 'neurais_merge', 'completo']\n",
    "classifier = 'LR'\n",
    "for c in conjunto:\n",
    "    for i in range(1, 5): #competencias\n",
    "        print(\"Comp \",i)\n",
    "        respostas = []\n",
    "        if classifier == 'LR': \n",
    "            parametros = {'comp': i, 'classifier': classifier,'tipo': c, 'p': {}}\n",
    "            respostas = treinar_classificador(parametros, 1)\n",
    "        else: #Floresta aleatoria, mudar o max_features conforme necessário\n",
    "            parametros = {'comp': i, 'classifier': classifier,'tipo': c, 'p': {'max_features': 'sqrt'}}\n",
    "            respostas = treinar_classificador(parametros, 100)\n",
    "        keys = respostas[0].keys()\n",
    "        nome_arquivo = f\"performance_{c}_{classifier}_{i}.csv\"\n",
    "        with open(nome_arquivo, 'w', newline='') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(respostas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c8651-79d0-46d6-a18c-b9f663b96e86",
   "metadata": {},
   "source": [
    "## Fazer seleção de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d4cc1-a516-4793-925e-9539a37618b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def selecionar_features(parametros, quantidade_features):\n",
    "    #retorna a média e desvio padrao em kappa e f1\n",
    "    dados_teste = get_novos_dados(parametros['comp'], parametros['tipo'])\n",
    "    teste = dados_teste['teste']\n",
    "    validacao = dados_teste['validacao']\n",
    "    y_teste = teste['competencia']\n",
    "    y_validacao = validacao['competencia']\n",
    "    teste_final = teste.drop('competencia', axis=1)\n",
    "    validacao_final = validacao.drop('competencia', axis=1)\n",
    "    lista_dic = []\n",
    "    features_selecionadas_originais = get_feature_selector(parametros['comp'], parametros['classifier'], parametros['tipo'], parametros['p'], {'n_features_to_select': quantidade_features+1, 'direction': \"forward\", 'seletor': 'SFS'})\n",
    "    for vez in range(1, quantidade_features+1):\n",
    "        features_selecionadas = get_feature_selector(parametros['comp'], parametros['classifier'], parametros['tipo'], parametros['p'], {'n_features_to_select': vez, 'direction': \"forward\", 'seletor': 'SFS'}, selecionar=features_selecionadas_originais)\n",
    "        print(vez, features_selecionadas)\n",
    "        rl = get_regressor(parametros['comp'], parametros['classifier'], parametros['tipo'], params=parametros['p'], selecionar=features_selecionadas)\n",
    "        #inferir na validacao\n",
    "        x = validacao_final[features_selecionadas].values\n",
    "        notas = rl.predict(x)\n",
    "        y_hat = arrumar_notas(notas)\n",
    "        dic_val = calcular_resultados(y_validacao, y_hat)\n",
    "        #inferir no teste\n",
    "        x = teste_final[features_selecionadas].values\n",
    "        notas = rl.predict(x)\n",
    "        y_hat = arrumar_notas(notas)\n",
    "        dic_teste = calcular_resultados(y_teste, y_hat)\n",
    "        #inferir com merge de treino e val\n",
    "        rl = get_regressor(parametros['comp'], parametros['classifier'], 'completo', params=parametros['p'], selecionar=features_selecionadas)\n",
    "        x = teste_final[features_selecionadas].values\n",
    "        notas = rl.predict(x)\n",
    "        y_hat = arrumar_notas(notas)\n",
    "        dic_teste_full = calcular_resultados(y_teste, y_hat)\n",
    "        lista_dic.append( {\"size_features\": vez, \"soma_validacao\": dic_val['F1'] + dic_val['KAPPA'], \"soma_teste\": dic_teste['F1'] + dic_teste['KAPPA'], \"soma_teste_full\": dic_teste_full['F1'] + dic_teste_full['KAPPA'],\n",
    "                           \"F1_validacao\": dic_val['F1'], \"KAPPA_validacao\": dic_val['KAPPA'], 'feature_list': features_selecionadas}  )\n",
    "    return lista_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96636149-fc1e-4aae-a6a0-c713325473ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto = ['completo_sem_merge', 'nao_neurais']\n",
    "classifier = 'LR'\n",
    "for c in conjunto:\n",
    "    for i in range(1, 5): #competencias\n",
    "        print(\"Comp \",i)\n",
    "        respostas = []\n",
    "        if classifier == 'LR': \n",
    "            parametros = {'comp': i, 'classifier': classifier,'tipo': c, 'p': {}}\n",
    "            respostas = selecionar_features(parametros, 10)\n",
    "        keys = respostas[0].keys()\n",
    "        nome_arquivo = f\"selecaoFeatures_{c}_{classifier}_{i}.csv\"\n",
    "        with open(nome_arquivo, 'w', newline='') as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(respostas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc2b0b-d9b3-4bb9-9c24-430214faa2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in conjunto:\n",
    "    for comp in range(1, 5):\n",
    "        nome_arquivo = f\"selecaoFeatures_{c}_{classifier}_{comp}.csv\"\n",
    "        dataset = pd.read_csv(nome_arquivo)\n",
    "        valor = max(dataset['soma_validacao'][:30])\n",
    "        pos = dataset['soma_validacao'].tolist().index(valor)\n",
    "        print(f\"Resultado do SFS: num features = {pos+1}, performance = {dataset['soma_teste_full'][pos]}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
